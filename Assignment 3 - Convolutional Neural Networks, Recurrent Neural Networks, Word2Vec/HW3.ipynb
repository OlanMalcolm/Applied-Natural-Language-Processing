{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c535e0",
   "metadata": {
    "id": "b32ba0fd"
   },
   "source": [
    "# Summer 2025 Applied NLP Homework 3\n",
    "\n",
    "## Instructors: Dr. Mahdi Roozbahani, Wafa Louhichi, Dr. Nimisha Roy\n",
    "\n",
    "## Deadline: July 4th, 11:59PM AoE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0518b841",
   "metadata": {
    "id": "eb689246"
   },
   "source": [
    "## Honor Code and Assignment Deadline\n",
    "<!-- No changes needed on the below section -->\n",
    "* No unapproved extension of the deadline is allowed. Late submission will lead to 0 credit. \n",
    "\n",
    "* Discussion is encouraged on Ed as part of the Q/A. However, all assignments should be done individually.\n",
    "\n",
    "* <font color='darkred'>Plagiarism is a **serious offense**. You are responsible for completing your own work. You are not allowed to copy and paste, or paraphrase, or submit materials created or published by others, as if you created the materials. All materials submitted must be your own.</font>\n",
    "\n",
    "* <font color='darkred'>All incidents of suspected dishonesty, plagiarism, or violations of the Georgia Tech Honor Code will be subject to the instituteâ€™s Academic Integrity procedures. If we observe any (even small) similarities/plagiarisms detected by Gradescope or our TAs, **WE WILL DIRECTLY REPORT ALL CASES TO OSI**, which may, unfortunately, lead to a very harsh outcome. **Consequences can be severe, e.g., academic probation or dismissal, grade penalties, a 0 grade for assignments concerned, and prohibition from withdrawing from the class.**\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b1a801",
   "metadata": {
    "id": "18717a84"
   },
   "source": [
    "## Instructions for the assignment \n",
    "\n",
    "<!-- No changes needed on the below section -->\n",
    "- This entire assignment will be autograded through Gradescope. There are two Gradescope submissions for this assignment:\n",
    "    - **Homework 3**: Submit files for Q0 to Q3 to this section \n",
    "    - **Homework 3 - Bonus EC (Optional)**: Submit the Bonus Q4 file to this section\n",
    "\n",
    "- We provided you different .py files and we added libraries in those files please DO NOT remove those lines and add your code after those lines. Note that these are the only allowed libraries that you can use for the homework.\n",
    "\n",
    "- You will submit your implemented .py files to the corresponding homework section on Gradescope. \n",
    "\n",
    "- You are allowed to make as many submissions until the deadline as you like. Additionally, note that the autograder tests each function separately, therefore it can serve as a useful tool to help you debug your code if you are not sure of what part of your implementation might have an issue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6483fd5",
   "metadata": {},
   "source": [
    "## Using the local tests <a id='using_local_tests'></a>\n",
    "- For some of the programming questions we have included a local test using a small toy dataset to aid in debugging. The local test sample data and outputs are stored in .py files in the **local_tests** folder\n",
    "- There are no points associated with passing or failing the local tests, you must still pass the autograder to get points. \n",
    "- **It is possible to fail the local test and pass the autograder** since the autograder has a certain allowed error tolerance while the local test allowed error may be smaller. Likewise, passing the local tests does not guarantee passing the autograder. \n",
    "- **You do not need to pass both local and autograder tests to get points, passing the Gradescope autograder is sufficient for credit.**\n",
    "- It might be helpful to comment out the tests for functions that have not been completed yet. \n",
    "- It is recommended to test the functions as it gets completed instead of completing the whole class and then testing. This may help in isolating errors. Do not solely rely on the local tests, continue to test on the autograder regularly as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def0a641",
   "metadata": {
    "id": "f3559faf"
   },
   "source": [
    "# Google Colab Setup (Optional for running on Colab)\n",
    "If you choose to work on the assignment on Google Colab, the following cell may help get you set up. You may need to right click on the Applied NLP folder and `Add shortcut to Drive`. You do not have to run this cell if you are working on the notebook locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f47504",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0066960d",
    "outputId": "ef5fd2e4-2d26-4f36-9115-3fcbbd7ec11e"
   },
   "outputs": [],
   "source": [
    "# # Mount google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "# # You may need to create an Applied_NLP/HW#/hw#_code/ folder\n",
    "# %cd '/content/drive/MyDrive/Applied_NLP/HW#/hw#_code/'\n",
    "\n",
    "# ## If no GPU selected it will ask for GPU to be selected\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#   print('and then re-execute this cell.')\n",
    "# else:\n",
    "#   print(gpu_info)\n",
    "\n",
    "\n",
    "# ## This wraps output text according to the window size\n",
    "# from IPython.display import HTML, display\n",
    "\n",
    "# def set_css():\n",
    "#   display(HTML('''\n",
    "#   <style>\n",
    "#     pre {\n",
    "#         white-space: pre-wrap;\n",
    "#     }\n",
    "#   </style>\n",
    "#   '''))\n",
    "# get_ipython().events.register('pre_run_cell', set_css)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7896fea",
   "metadata": {
    "id": "05409a58"
   },
   "source": [
    "# Assignment Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682b08c5",
   "metadata": {
    "id": "89d96973"
   },
   "source": [
    "In this homework we will explore non-linear text classification algorithms : Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). We will also look into another embedding techique : Word2Vec.\n",
    "\n",
    "We will reuse the datasets from HW2 for this exploration:\n",
    "* The first dataset is a subset of a [Clickbait Dataset](https://github.com/bhargaviparanjape/clickbait/tree/master/dataset) that has article headlines and a binary label on whether the headline is considered clickbait. \n",
    "* The second dataset is a subset of [Web of Science Dataset](https://data.mendeley.com/datasets/9rw3vkcfy4/6) that has articles and a corresponding label on the domain of the articles. \n",
    "\n",
    "We will first explore Continuous Bag-of-Words (CBOW) and Skip-gram based Word2Vec models using a very small dataset. We will then use pre-trained Word2Vec embeddings and feed them to the classification algorithms.\n",
    "\n",
    "As a bonus exercise, you will have the opportunity to write your own training loop to train a simple two layer neural net.\n",
    "\n",
    "**You will be using pytorch for coding the models in this homework. If you are new to PyTorch, we have listed several tutorials in the PyTorch Resources section to get you started.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741da6c",
   "metadata": {
    "id": "e51f68d8"
   },
   "source": [
    "## Deliverables and Points Distribution\n",
    "\n",
    "### Q0: Loading PyTorch State Dict Example [5pts]\n",
    "- **Fixing the Given Function** [5pts] Deliverables: <font color = 'green'>q0_example.py</font>\n",
    "\n",
    "    - [4pts] init\n",
    "\n",
    "    - [1pts] forward\n",
    "\n",
    "### Q1: Word2Vec [45pts]\n",
    "- **1.1 Implementing CBOW from Scratch** [26pts] Deliverables: <font color = 'green'>word2vec.py</font>\n",
    "\n",
    "    - [2pts] tokenize (Word2Vec class)\n",
    "\n",
    "    - [5pts] create_vocabulary (Word2Vec class)\n",
    "\n",
    "    - [10pts] cbow_embeddings (Word2Vec class)\n",
    "\n",
    "    - [4pts] \\_\\_init__ (CBOW_Model class)\n",
    "    \n",
    "    - [5pts] forward (CBOW_Model class)\n",
    "\n",
    "- **1.2 Implementing Skip-Gram from Scratch** [19pts] Deliverables: <font color = 'green'>word2vec.py</font>\n",
    "\n",
    "    - [10pts] skipgram_embeddings (Word2Vec class)\n",
    "\n",
    "    - [4pts] \\_\\_init__ (SkipGram_Model class)\n",
    "\n",
    "    - [5pts] forward (SkipGram_Model class)\n",
    "\n",
    "### Q2: Classification with CNN [15pts]\n",
    "- **2.1 Implementing CNN** [10pts] Deliverables: <font color = 'green'>cnn.py</font>\n",
    "\n",
    "    - [3pts] \\_\\_init__\n",
    "\n",
    "    - [7pts] forward\n",
    "        - [2pts] forward_embed\n",
    "        - [3pts] forward_convs\n",
    "        - [2pts] forward\n",
    "- **2.3: Classifying Web of Science Dataset using CNN** [5pts] Deliverables: <font color = 'green'>cnn.py and best_cnn_model.pt</font>\n",
    "\n",
    "### Q3: Classification with RNN [15pts]\n",
    "- **3.1 Implementing RNN** [10pts] Deliverables: <font color = 'green'>rnn.py</font>\n",
    "\n",
    "    - [2pts] \\_\\_init__ \n",
    "\n",
    "    - [8pts] forward \n",
    "        - [2pts] forward_embed\n",
    "        - [2pts] forward_rnn\n",
    "        - [2pts] forward_concat\n",
    "        - [2pts] forward\n",
    "- **3.2: Classifying Clickbait Dataset using RNN** [5pts] Deliverables: <font color = 'green'>rnn.py and best_rnn_model.pt</font>   \n",
    "\n",
    "### Q4: Classification with NN (4pts Bonus Extra Credit)\n",
    "- **(Submit to Bonus Extra Credit section in Gradescope)**\n",
    "- **4.1 Implementing NN** [2pts] Deliverables: <font color = 'green'>nn.py</font>\n",
    "\n",
    "    - [2pts] \\_\\_init__\n",
    "\n",
    "- **4.4: Classifying Web of Science Dataset using NN** [2pts] Deliverables: <font color = 'green'>nn.py and best_nn_model.pt</font> \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986fdd3a",
   "metadata": {},
   "source": [
    "# PyTorch Resources <a id='pytorch_resources'></a>\n",
    "\n",
    "If you are new to PyTorch, you may find it helpful to go through the reference links below. Each link has an option to open the page directly in Google Colab so that you can run the cells and directly interact with the content:\n",
    "\n",
    "- [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html): This tutorial will introduce you to dataloaders, creating a simple neural net, optimizing the parameters, and saving/loading models. \n",
    "\n",
    "- [Build Model](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html): This tutorial will explain the layers that were used in creating the simple neural net from Quickstart and also show you how to examine the layers and parameters of your neural net.\n",
    "\n",
    "- [Optimization](https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#optimization-loop): This tutorial will go over hyperparameters, choosing a loss function, and explaining steps in the training and testing loop. \n",
    "\n",
    "- What is a [tensor](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) and helpful functions to manipulate a tensor: [reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html), [view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html), [squeeze](https://pytorch.org/docs/stable/generated/torch.squeeze.html), [unsqueeze](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html), [flatten](https://pytorch.org/docs/stable/generated/torch.flatten.html), [cat](https://pytorch.org/docs/stable/generated/torch.cat.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd28272",
   "metadata": {
    "id": "f462ddb9"
   },
   "source": [
    "# Setup\n",
    "**Please checkout the environment_setup.md file to create the environment for this homework.** This notebook is tested under the package versions noted in the Library Imports cell output below, and the corresponding packages can be downloaded from [miniconda](https://docs.conda.io/en/latest/miniconda.html). You may also want to get yourself familiar with several packages:\n",
    "\n",
    "- [jupyter notebook](https://jupyter-notebook.readthedocs.io/en/stable/)\n",
    "- [numpy](https://docs.scipy.org/doc/numpy-1.15.1/user/quickstart.html)\n",
    "- [sklearn](https://matplotlib.org/users/pyplot_tutorial.html)\n",
    "- [pytorch](https://pytorch.org/)\n",
    "\n",
    "In the .py files please implement the functions that have `raise NotImplementedError`, and after you finish the coding, please delete or comment out `raise NotImplementedError`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e2f73e",
   "metadata": {
    "id": "f056b4ff"
   },
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45287e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If using Google Colab, uncomment this cell and run\n",
    "# !pip uninstall torch torchaudio\n",
    "# !pip install torch==2.2.2 torchtext torchaudio gensim scipy==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4327d4bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "id": "73b47510",
    "outputId": "28d7ed83-92ab-4951-de7e-79679cc41ee6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version information\n",
      "python: 3.12.11 | packaged by Anaconda, Inc. | (main, Jun  5 2025, 08:03:38) [Clang 14.0.6 ]\n",
      "pandas: 2.2.3\n",
      "numpy: 1.26.4\n",
      "scipy: 1.12.0\n",
      "sns: 0.13.2\n",
      "gensim: 4.3.3\n",
      "torchtext: 0.17.2\n",
      "sklearn: 1.6.1\n",
      "torch: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sys, re, pickle, random\n",
    "from copy import deepcopy\n",
    "import seaborn as sns\n",
    "import gensim             \n",
    "import torchtext\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "torch.manual_seed(10)\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "print('Version information')\n",
    "\n",
    "print('python: {}'.format(sys.version))\n",
    "print('pandas: {}'.format(pd.__version__))\n",
    "print('numpy: {}'.format(np.__version__))\n",
    "print('scipy: {}'.format(sp.__version__))\n",
    "print('sns: {}'.format(sns.__version__))\n",
    "print('gensim: {}'.format(gensim.__version__))        \n",
    "print('torchtext: {}'.format(torchtext.__version__))\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "print('torch: {}'.format(torch.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0372f",
   "metadata": {
    "id": "eff26cb3"
   },
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb811f0c",
   "metadata": {
    "id": "837cc1e5"
   },
   "source": [
    "We start by loading both data sets already split into an 80/20 train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a13f73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "e2b97025",
    "outputId": "391ea7e2-f53d-40d4-cd91-d7989f239c7e"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_test = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train, y_train = list(df_train['headline']), list(df_train['label'])\n",
    "x_test, y_test = list(df_test['headline']), list(df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57087a33",
   "metadata": {
    "id": "15f2a21c"
   },
   "source": [
    "Below is the number of headlines in the train and test set as well as a sample of the article headlines and its binary label, where 0 is considered not clickbait and 1 is clickbait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fba40c60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "11e3ebf5",
    "outputId": "97c351fe-624d-4b6c-b8e2-1cf03ad30dd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Headlines: 19200\n",
      "Number of Test Headlines: 4800\n",
      "\n",
      "\n",
      "Sample Label and Headlines:\n",
      "1: 27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\n",
      "\n",
      "1: 22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\n",
      "\n",
      "0: PepsiCo Profit Falls 43 Percent\n",
      "\n",
      "0: Website of Bill O'Reilly, FOX News commentator, hacked in retribution\n",
      "\n",
      "1: The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\n",
      "\n",
      "\n",
      "Output of Sample Headlines without Print Statement:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['27 Breathtaking Alternatives To A Traditional Wedding Bouquet <br>\\n',\n",
       " \"22 Pictures People Who Aren't Grad Students Will <strong>Never</strong> Understand\\n\",\n",
       " 'PepsiCo Profit Falls 43 Percent\\n',\n",
       " \"Website of Bill O'Reilly, FOX News commentator, hacked in retribution\\n\",\n",
       " 'The Green Toy Soldiers From Your Childhood Now Come In Baller Yoga Poses A\\n']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "print(f'Number of Train Headlines: {len(x_train)}')\n",
    "print(f'Number of Test Headlines: {len(x_test)}')\n",
    "\n",
    "print('\\n\\nSample Label and Headlines:')\n",
    "x = 105\n",
    "for label, line in zip(y_train[x:x+5], x_train[x:x+5]):\n",
    "    print(f'{label}: {line}')\n",
    "    \n",
    "print('\\nOutput of Sample Headlines without Print Statement:')\n",
    "x_train[x:x+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50709ad0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "20a8debc",
    "outputId": "2d934897-8f6f-49bb-a85c-d627017dd8b0"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "df_train_wos = pd.read_csv('./data/train_wos.csv')\n",
    "df_test_wos = pd.read_csv('./data/test_wos.csv')\n",
    "\n",
    "# Separate dataframes into train and test lists\n",
    "x_train_wos, y_train_wos = list(df_train_wos['article']), list(df_train_wos['label'])\n",
    "x_test_wos, y_test_wos = list(df_test_wos['article']), list(df_test_wos['label'])\n",
    "\n",
    "# Numerical label to domain mapping\n",
    "wos_label = {0:'CS', 1:'ECE', 2:'Civil', 3:'Medical'}\n",
    "# Numerical label to Numerical mapping\n",
    "label_mapping = {0:0, 1:1, 4:2, 5:3}\n",
    "\n",
    "for i, label in enumerate(y_train_wos):\n",
    "    y_train_wos[i] = label_mapping[label]\n",
    "for i, label in enumerate(y_test_wos):\n",
    "    y_test_wos[i] = label_mapping[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63a28b0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "d24ac5b6",
    "outputId": "f5df643b-a8d5-41de-cba7-eede9bbaa59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Train Articles: 1600\n",
      "Number of Test Articles: 400\n",
      "\n",
      "Label Key: {0: 'CS', 1: 'ECE', 2: 'Civil', 3: 'Medical'}\n",
      "\n",
      "Sample Label and Articles:\n",
      "\n",
      "0 - CS: An efficient procedure for calculating the electromagnetic fields in multilayered cylindrical structures is reported in this paper. Using symbolic computation, spectral Green's functions, suitable for numerical implementations are determined in compact and closed forms. Applications are presented for structures with two dielectric layers.\n",
      "\n",
      "1 - ECE: A multifunctional platform based on the microhotplate was developed for applications including a Pirani vacuum gauge, temperature, and gas sensor. It consisted of a tungsten microhotplate and an on-chip operational amplifier. The platform was fabricated in a standard complementary metal oxide semiconductor (CMOS) process. A tungsten plug in standard CMOS process was specially designed as the serpentine resistor for the microhotplate, acting as both heater and thermister. With the sacrificial layer technology, the microhotplate was suspended over the silicon substrate with a 340 nm gap. The on-chip operational amplifier provided a bias current for the microhotplate. This platform has been used to develop different kinds of sensors. The first one was a Pirani vacuum gauge ranging from 10(-1) to 10(5) Pa. The second one was a temperature sensor ranging from -20 to 70 degrees C. The third one was a thermal-conductivity gas sensor, which could distinguish gases with different thermal conductivities in constant gas pressure and environment temperature. In the fourth application, with extra fabrication processes including the deposition of gas-sensitive film, the platform was used as a metal-oxide gas sensor for the detection of gas concentration.\n",
      "\n",
      "2 - Civil: Artificial neural networks have been effectively used in various civil engineering fields, including construction management and labour productivity. In this study, the performance of the feed forward neural network (FFNN) was compared with radial basis neural network (RBNN) in modelling the productivity of masonry crews. A variety of input factors were incorporated and analysed. Mean absolute percentage error (MAPE) and correlation coefficient (R) were used to evaluate model performance. Research results indicated that the neural computing techniques could be successfully employed in modelling crew productivity. It was also found that successful models could be developed with different combinations of input factors, and several of the models which excluded one or more input factors turned out to be better than the baseline models. Based on the MAPE values obtained for the models, the RBNN technique was found to be better than the FFNN technique, although both slightly overestimated the masons' productivity.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "print(f'Number of Train Articles: {len(x_train_wos)}')\n",
    "print(f'Number of Test Articles: {len(x_test_wos)}')\n",
    "\n",
    "print('\\nLabel Key:', wos_label)\n",
    "\n",
    "print('\\nSample Label and Articles:\\n')\n",
    "x = 107\n",
    "for label, line in zip(y_train_wos[x:x+3], x_train_wos[x:x+3]):\n",
    "    print(f'{label} - {wos_label[label]}: {line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652028d5",
   "metadata": {},
   "source": [
    "# Q0: Loading PyTorch State Dict Example [5pts]\n",
    "\n",
    "Throughout this assignment, we will load basic state dictionaries into your PyTorch model to ensure the same layer initializations for \n",
    "local test use. In order for the basic state dicts to load, the layer names and the layer shapes must match between the model and the state dict, otherwise errors will occur. Q0 will show you some of these errors and you will need to address them to get points for this section.\n",
    "\n",
    "In addition to using state dicts for the local test, we will also save the state dicts of your trained model to use for the Gradescope Accuracy tests. Any mismatch in layer names or layer shapes between your submitted state dict .pt file and actual model code in your submitted .py files may result in errors similar to the ones you will encounter in this question. \n",
    "\n",
    "In the **q0_example.py** file, fix the following functions that have been implemented incorrectly:\n",
    "  * <strong>init</strong>\n",
    "  * <strong>forward</strong>\n",
    "\n",
    "If you are new to PyTorch, you may want to review the [PyTorch Resources](#pytorch_resources) section.\n",
    "\n",
    "Run the following local test to see the errors and fix the errors in the **q0_example.py** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a097846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for Q0 Example \n",
      "\n",
      "Your init works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from q0_example import Q0\n",
    "from local_tests.q0_test import Q0_Test\n",
    "\n",
    "local_test = Q0_Test()\n",
    "q0_model = Q0()\n",
    "\n",
    "print('Local Tests for Q0 Example \\n')\n",
    "\n",
    "# Local test for init\n",
    "init_test = True if q0_model.load_state_dict(torch.load('./local_tests/basic_q0_model.pt')) else False\n",
    "print('Your init works as expected:', init_test) \n",
    "\n",
    "# Local test for forward\n",
    "output = q0_model(local_test.sample_input)\n",
    "forward_test = (torch.allclose(output, local_test.sample_output, rtol=0.0001, atol=0.0001) and \\\n",
    "                output.shape == local_test.sample_output.shape)\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e102be8",
   "metadata": {
    "id": "7M6Npz6qFN1q"
   },
   "source": [
    "# Q1: Word2Vec [45pts]\n",
    "\n",
    "Word2vec is a method to efficiently create word embeddings. More details on word2vec and the intuition behind it can be found here :  \n",
    "* [The Illustrated Word2vec by Jay Alammar](https://jalammar.github.io/illustrated-word2vec/)\n",
    "\n",
    "Word2vec is based on the idea that a wordâ€™s meaning is defined by its context. Context is represented as surrounding words. For the word2vec model, context is represented as N words before and N words after the current word. N is a hyperparameter. With larger N we can create better embeddings, but at the same time, such a model requires more computational resources. \n",
    "\n",
    "There are two word2vec architectures proposed in the paper:\n",
    "\n",
    "* CBOW (Continuous Bag-of-Words) â€” a model that predicts a current word based on its context words.\n",
    "* Skip-Gram â€” a model that predicts context words based on the current word.\n",
    "\n",
    "We will be running our Word2Vec models on a very small dataset as described below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "336764cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "mC1mB6pYqP4U",
    "outputId": "41393f89-e928-40c9-c875-e603e36affd9"
   },
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'he is a king',\n",
    "    'she is a queen',\n",
    "    'he is a man',\n",
    "    'she is a woman',\n",
    "    'warsaw is poland capital',\n",
    "    'berlin is germany capital',\n",
    "    'paris is france capital'  \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78aa53",
   "metadata": {
    "id": "-Np3UUmtFUjd"
   },
   "source": [
    "## 1.1: Implementing Continuous Bag-of-words From Scratch [26pts]\n",
    "In the **word2vec.py** file complete the following functions:\n",
    "  * <strong>tokenize</strong> (Word2Vec class)\n",
    "  * <strong>create_vocabulary</strong> (Word2Vec class)\n",
    "  * <strong>cbow_embeddings</strong> (Word2Vec class)\n",
    "  * <strong>\\_\\_init__</strong> (CBOW_Model class)\n",
    "  * <strong>forward</strong> (CBOW_Model class)\n",
    "\n",
    "A high level overview of the CBOW model can be described as :    \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*ETcgajy5s0KNIfMgE5xOqg.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "CBOW model takes several words, each goes through the same Embedding layer, and then word embedding vectors are averaged before going into the Linear layer.\n",
    "\n",
    "We will be implementing this model using the architecture described below :    \n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/1400/1*mLDM3PH12CjhaFoUm5QTow.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "Here are the steps that needs to be followed for implementing CBOW model :    \n",
    "* Step-1: Create vocabulary\n",
    "  * Split each words into tokens.\n",
    "  * Assign a unique ID to each unique token.\n",
    "\n",
    "* Step-2: Create CBOW Embeddings\n",
    "  * Create CBOW embeddings by taking context as N past words and N future words.\n",
    "\n",
    "* Step-3: Implement CBOW Model\n",
    "  * Implement CBOW model as described in the architecture above.\n",
    "  \n",
    "<b>Hint:</b> Since we are using the cross entropy loss, there is no need to apply the softmax after the linear layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a21d6f",
   "metadata": {},
   "source": [
    "### 1.1.1: Local Tests for CBOW Functions [No Points]\n",
    "You may test your implementation of the CBOW functions contained in **word2vec.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details.\n",
    "\n",
    "ðŸ¦Š *Hint: Did you know that pytorch state dicts are dictionaries? You can load the basic_cbow_model.pt file into a variable to see the expected shapes of the layers and compare to your model's initalized layer shapes. See line 32 for an example on how to access the cbow model's state dict. Feel free to try this out for other models in this homework.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb288bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for Word2Vec & CBOW Functions \n",
      "\n",
      "Your tokenize works as expected: True\n",
      "Your create_vocabulary works as expected: True\n",
      "Your cbow_embeddings works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec, CBOW_Model\n",
    "from local_tests.word2vec_test import Word2Vec_Test\n",
    "\n",
    "local_test = Word2Vec_Test()\n",
    "stu_w2v = Word2Vec()\n",
    "\n",
    "print('Local Tests for Word2Vec & CBOW Functions \\n')\n",
    "\n",
    "# Local test for tokenize\n",
    "output = stu_w2v.tokenize(local_test.corpus_data)\n",
    "tokens_test = (output == local_test.tokens)\n",
    "print('Your tokenize works as expected:', tokens_test)\n",
    "\n",
    "# Local test for create_vocabulary\n",
    "stu_w2v.create_vocabulary(local_test.tokens)\n",
    "create_vocab_test = ((stu_w2v.word2idx == local_test.word2idx) and (stu_w2v.idx2word == local_test.idx2word) and \\\n",
    "                     (stu_w2v.vocabulary_size == local_test.vocab_size))\n",
    "print('Your create_vocabulary works as expected:', create_vocab_test)\n",
    "\n",
    "# Local test for cbow_embeddings\n",
    "source, target = stu_w2v.cbow_embeddings(local_test.tokens)\n",
    "cbow_embed_test = ((source == local_test.cbow_source) and (target == local_test.cbow_target))\n",
    "print('Your cbow_embeddings works as expected:', cbow_embed_test)\n",
    "\n",
    "# Instantiate CBOW_Model and load weights for local tests\n",
    "torch.manual_seed(10)\n",
    "cbow_model = CBOW_Model(local_test.vocab_size)\n",
    "cbow_state_dict = cbow_model.state_dict()\n",
    "\n",
    "# If loading the state dict causes an error, then there may be an issue with your init implementation\n",
    "cbow_model.load_state_dict(torch.load('./local_tests/basic_cbow_model.pt'))\n",
    "\n",
    "# Local test for forward\n",
    "outputs = []\n",
    "for i in range(len(local_test.cbow_source)):\n",
    "    output = cbow_model(torch.from_numpy(np.array(local_test.cbow_source[i])))\n",
    "    output_test = (torch.allclose(output, local_test.cbow_forward[i], rtol=0.0001, atol=0.0001) and \\\n",
    "                      output.shape == local_test.cbow_forward[i].shape)\n",
    "    outputs.append(output_test)\n",
    "forward_test = np.all(outputs)\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fc678",
   "metadata": {
    "id": "jd9OaAf9qZ5r"
   },
   "source": [
    "### 1.1.2: Fetching CBOW embeddings [No Points]\n",
    "Run the below cell to fetch CBOW embeddings using functions that you have already implemented in **1.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da6c0513",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "6bd51ab7",
    "outputId": "2ecda65b-64cc-458b-9c1c-102cb0a9e7b1"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec()\n",
    "tokens = w2v.tokenize(corpus)\n",
    "w2v.create_vocabulary(tokens)\n",
    "source, target = w2v.cbow_embeddings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4476d1",
   "metadata": {
    "id": "3t3BiUU1rMM6"
   },
   "source": [
    "### 1.1.3: Training CBOW model [No Points]\n",
    "Run the below cell to train CBOW model using functions that you have already implemented in **1.1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5c7f0c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "1fCSFxldedmf",
    "outputId": "6dc04ce3-941e-409e-8a62-e758b2ad4f3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 75.629929\n",
      "loss on epoch 20: 43.497833\n",
      "loss on epoch 40: 33.148113\n",
      "loss on epoch 60: 28.147776\n",
      "loss on epoch 80: 25.390455\n",
      "loss on epoch 100: 23.779957\n",
      "loss on epoch 120: 22.416714\n",
      "loss on epoch 140: 21.473902\n",
      "loss on epoch 160: 21.049877\n",
      "loss on epoch 180: 20.514498\n",
      "loss on epoch 200: 20.258718\n",
      "loss on epoch 220: 19.946516\n",
      "loss on epoch 240: 19.544521\n",
      "loss on epoch 260: 19.617466\n",
      "loss on epoch 280: 19.282171\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import CBOW_Model\n",
    "\n",
    "N_EPOCHS = 300\n",
    "model = CBOW_Model(w2v.vocabulary_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(target)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    for i in shuffled_i:\n",
    "        x = torch.from_numpy(np.asarray(source[i])).long().to(device)\n",
    "        y = torch.from_numpy(np.asarray(target[i])).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 20 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f69474",
   "metadata": {
    "id": "GvdTvbADsOgr"
   },
   "source": [
    "### 1.1.4: Visualizing CBOW embeddings [No Points]\n",
    "Run the below cells to visualize CBOW embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9fa48b34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "pgmVkIigg1xr",
    "outputId": "94f2ec1e-dfe6-4c7d-ab93-adbd4785d308"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# embedding from first model layer\n",
    "embeddings = list(model.parameters())[0]\n",
    "embeddings = embeddings.cpu().detach().numpy()\n",
    "\n",
    "# normalization\n",
    "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
    "norms = np.reshape(norms, (len(norms), 1))\n",
    "embeddings_norm = embeddings / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c652902",
   "metadata": {},
   "source": [
    "Here, we use truncated SVD to project the learned word2vec embedding to 2D space for visualization. Feel free to tune the learning rate in the training part for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ef015a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "PYcXX6AIpcun",
    "outputId": "6a76217b-527b-410c-ae23-e81eccd32115"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import decomposition\n",
    "\n",
    "w2v.word2idx[''] = 0\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W2_dec = svd.fit_transform(embeddings)\n",
    "\n",
    "x = W2_dec[:,0]\n",
    "y = W2_dec[:,1]\n",
    "plot = sns.scatterplot(x=x, y=y)\n",
    "\n",
    "for i in range(0,W2_dec.shape[0]):\n",
    "     plot.text(x[i], y[i]+2e-2, list(w2v.word2idx)[i], horizontalalignment='center', size='small', color='black', weight='semibold');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1a1b1",
   "metadata": {},
   "source": [
    "Here, we will look into the learned property of the word2vec embedding. Warsaw is the capital of Poland and we now calculate the difference between embeddings of \"warsaw\" and \"poland\". After that, we add the difference to the embedding of \"paris\". We then rank the dot product of the computed embedding vs all the embeddings. Notice that the larger this value, the more similar two embeddings are. Feel free to play with different word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "328d2759",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "3V4LYCq5mVB1",
    "outputId": "c652ce3a-0ca3-49f6-ec29-d1b22c0fdb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poland: 0.691\n",
      "paris: 0.479\n",
      "germany: 0.260\n",
      "france: 0.141\n",
      "woman: 0.027\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeddings[w2v.word2idx[\"poland\"]]\n",
    "emb2 = embeddings[w2v.word2idx[\"warsaw\"]]\n",
    "emb3 = embeddings[w2v.word2idx[\"paris\"]]\n",
    "\n",
    "emb4 = emb1 - emb2 + emb3\n",
    "emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n",
    "emb4 = emb4 / emb4_norm\n",
    "\n",
    "emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "for word_id in top5:\n",
    "    print(\"{}: {:.3f}\".format(w2v.idx2word[word_id], dists[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84aa0b",
   "metadata": {
    "id": "4TLUiFFR7wlL"
   },
   "source": [
    "## 1.2: Implementing Skip-Gram From Scratch [19pts]\n",
    "In the **word2vec.py** file complete the following functions:\n",
    "  * <strong>skipgram_embeddings</strong> (Word2Vec class)\n",
    "  * <strong>\\_\\_init__</strong> (SkipGram_Model class)\n",
    "  * <strong>forward</strong> (SkipGram_Model class)\n",
    "\n",
    "A high level overview of the SkipGram model can be described as :    \n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/720/1*SVs6xTpD7AYviP24UTOYUA.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "The Skip-Gram model takes a single word as compared to CBOW model.\n",
    "\n",
    "We will be implementing this model using the architecture described below :    \n",
    "\n",
    "<p align=\"center\"><img src=\"https://miro.medium.com/max/720/1*eHh1_t8Wms_hqDNBLuAnFg.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "Here are the steps that needs to be followed for implementing SkipGram model :    \n",
    "* Step-1: Create vocabulary\n",
    "  * Split each words into tokens.\n",
    "  * Assign a unique ID to each unique token.\n",
    "\n",
    "* Step-2: Create SkipGram Embeddings\n",
    "  * Create SkipGram embeddings by taking context as middle word.\n",
    "\n",
    "* Step-3: Implement SkipGram Model\n",
    "  * Implement SkipGram model as described in the architecture above. Output SkipGram embeddings for N past words and N future words.\n",
    "\n",
    "**Hint:** Since we are using the cross entropy loss, there is no need to apply the softmax after the linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f8890",
   "metadata": {},
   "source": [
    "### 1.2.1: Local Tests for SkipGram Functions [No Points]\n",
    "You may test your implementation of the SkipGram functions contained in **word2vec.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f255a763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for Skipgram Functions \n",
      "\n",
      "Your skipgram_embeddings works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec, SkipGram_Model\n",
    "from local_tests.word2vec_test import Word2Vec_Test\n",
    "\n",
    "local_test = Word2Vec_Test()\n",
    "stu_w2v = Word2Vec()\n",
    "stu_w2v.create_vocabulary(local_test.tokens)\n",
    "\n",
    "print('Local Tests for Skipgram Functions \\n')\n",
    "\n",
    "# Local test for skipgram_embeddings\n",
    "source, target = stu_w2v.skipgram_embeddings(local_test.tokens)\n",
    "skipgram_embed_test = ((source == local_test.sg_source) and (target == local_test.sg_target))\n",
    "print('Your skipgram_embeddings works as expected:', skipgram_embed_test)\n",
    "\n",
    "# Instantiate SkipGram_Model and load weights for local tests\n",
    "torch.manual_seed(10)\n",
    "sg_model = SkipGram_Model(local_test.vocab_size)\n",
    "# If loading the state dict causes an error, then there may be an issue with your init implementation\n",
    "sg_model.load_state_dict(torch.load('./local_tests/basic_sg_model.pt'))\n",
    "\n",
    "# Local test for forward\n",
    "output = sg_model(torch.from_numpy(np.array(local_test.sg_source[:12])).squeeze())\n",
    "forward_test = (torch.allclose(output, local_test.sg_forward, rtol=0.0001, atol=0.0001) and \\\n",
    "                      output.shape == local_test.sg_forward.shape)\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82623a",
   "metadata": {
    "id": "IVCLHrC788LU"
   },
   "source": [
    "### 1.2.2: Fetching SkipGram embeddings [No Points]\n",
    "Run the below cell to fetch **SkipGram** embeddings using functions that you have already implemented in 1.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf77f75b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ecu9TMvO83p9",
    "outputId": "f658bea1-dbdc-4867-d1fd-9b0bf25cc2e7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec()\n",
    "tokens = w2v.tokenize(corpus)\n",
    "w2v.create_vocabulary(tokens)\n",
    "source, target = w2v.skipgram_embeddings(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53275506",
   "metadata": {
    "id": "4lU_G6iB9N9d"
   },
   "source": [
    "### 1.2.3: Training SkipGram model [No Points]\n",
    "Run the below cell to train SkipGram model using functions that you have already implemented in **1.2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b4b39c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "JGRhDekI83si",
    "outputId": "c7fec093-54d0-4b8a-95b0-21b5030e6fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 188.967102\n",
      "loss on epoch 20: 125.359100\n",
      "loss on epoch 40: 118.982780\n",
      "loss on epoch 60: 116.689804\n",
      "loss on epoch 80: 116.032486\n",
      "loss on epoch 100: 115.774033\n",
      "loss on epoch 120: 115.291489\n",
      "loss on epoch 140: 115.532127\n",
      "loss on epoch 160: 114.594604\n",
      "loss on epoch 180: 114.136116\n",
      "loss on epoch 200: 114.540497\n",
      "loss on epoch 220: 114.383560\n",
      "loss on epoch 240: 113.384697\n",
      "loss on epoch 260: 113.919945\n",
      "loss on epoch 280: 113.587914\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from word2vec import SkipGram_Model\n",
    "\n",
    "N_EPOCHS = 300\n",
    "model = SkipGram_Model(w2v.vocabulary_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(target)))\n",
    "    random.shuffle(shuffled_i)\n",
    "    for i in shuffled_i:\n",
    "        x = torch.from_numpy(np.asarray(source[i])).long().to(device)\n",
    "        y = torch.from_numpy(np.asarray(target[i])).long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if epoch % 20 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82724a35",
   "metadata": {
    "id": "HOthB5MD9ruv"
   },
   "source": [
    "### 1.2.4: Visualizing SkipGram embeddings [No Points]\n",
    "Run the below cells to visualize SkipGram embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3286dea0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MW64QQ4n83vK",
    "outputId": "acb32f8c-6dde-4277-c519-fa9a1977c548"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# embedding from first model layer\n",
    "embeddings = list(model.parameters())[0]\n",
    "embeddings = embeddings.cpu().detach().numpy()\n",
    "\n",
    "# normalization\n",
    "norms = (embeddings ** 2).sum(axis=1) ** (1 / 2)\n",
    "norms = np.reshape(norms, (len(norms), 1))\n",
    "embeddings_norm = embeddings / norms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99573626",
   "metadata": {},
   "source": [
    "Here, we use truncated SVD to project the learned word2vec embedding to 2D space for visualization. Feel free to tune the learning rate in the training part for different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe8b545d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "iLhTgwE183xt",
    "outputId": "832755ed-5da8-47b4-eb4a-41d15f938d65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn import decomposition\n",
    "\n",
    "w2v.word2idx[''] = 0\n",
    "svd = decomposition.TruncatedSVD(n_components=2)\n",
    "W2_dec = svd.fit_transform(embeddings)\n",
    "\n",
    "x = W2_dec[:,0]\n",
    "y = W2_dec[:,1]\n",
    "plot = sns.scatterplot(x=x, y=y)\n",
    "\n",
    "for i in range(0,W2_dec.shape[0]):\n",
    "     plot.text(x[i], y[i]+2e-2, list(w2v.word2idx)[i], horizontalalignment='center', size='small', color='black', weight='semibold');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f25d5c",
   "metadata": {},
   "source": [
    "Here, we will look into the learned property of the word2vec embedding. Warsaw is the capital of Poland and we now calculate the difference between embeddings of \"warsaw\" and \"poland\". After that, we add the difference to the embedding of \"paris\". We then rank the dot product of the computed embedding vs all the embeddings. Notice that the larger this value, the more similar two embeddings are. Feel free to play with different word pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "071b93a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "6Opu7Awy979w",
    "outputId": "058539e5-171d-4c34-b086-5a283fc82684"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poland: 0.707\n",
      "paris: 0.481\n",
      "germany: 0.419\n",
      "france: 0.402\n",
      "woman: 0.193\n"
     ]
    }
   ],
   "source": [
    "emb1 = embeddings[w2v.word2idx[\"poland\"]]\n",
    "emb2 = embeddings[w2v.word2idx[\"warsaw\"]]\n",
    "emb3 = embeddings[w2v.word2idx[\"paris\"]]\n",
    "\n",
    "emb4 = emb1 - emb2 + emb3\n",
    "emb4_norm = (emb4 ** 2).sum() ** (1 / 2)\n",
    "emb4 = emb4 / emb4_norm\n",
    "\n",
    "emb4 = np.reshape(emb4, (len(emb4), 1))\n",
    "dists = np.matmul(embeddings_norm, emb4).flatten()\n",
    "\n",
    "top5 = np.argsort(-dists)[:5]\n",
    "\n",
    "for word_id in top5:\n",
    "    print(\"{}: {:.3f}\".format(w2v.idx2word[word_id], dists[word_id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec1dcea",
   "metadata": {
    "id": "DqJwpMAYUg4A"
   },
   "source": [
    "Ideally with large amount of data, we should have got france as the most nearest word. But depending on the implementation and amount of data, it can vary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aeccece",
   "metadata": {
    "id": "dRvybL9rYxcQ"
   },
   "source": [
    "# Q2: Classification with CNN [15pts]\n",
    "\n",
    "Convolutional layers are used to find patterns by sliding a small kernel window over the input. In computer vision applications, the kernel window slides through and gets multiplied by small regions in an image. In the context of NLP, the kernel slides through and gets multiplied by the embedding vectors of a few words as specified by window size. For looking at sequences of word embeddings, the window has to look at multiple word embeddings in a sequence. The kernel will be rectangular with size window_size x embedding_size. For example, if window size is 3 then the kernel size will be 3 x 500. This essentially represents n-grams in the model. The kernel weights (filter) are multiplied to word embeddings in pairs and summed up to get output values. As the network is being learned, these kernel weights are also being learned.\n",
    "\n",
    "CNNs, in the context of NLP, are tasks like spam detection and recognizing patterns and anomalies in small texts. This ability allows them to quickly filter out irrelevant or harmful content. However, CNNs suffer on tasks that depend on a lot of context, like multi-message chats or long documents.\n",
    "\n",
    "Let's explore the power of CNNs by implementing a convolutional neural network with a pre-trained word2vec model for classification similar to the CNN-rand baseline described by [Kim (2014)](https://aclanthology.org/D14-1181.pdf). Although our model differs from the paper, it may still be helpful to review the model section of the paper to get a general overview of the architecture. We will use a pre-trained word2vec model for feasibility of finding the appropriate embeddings. The architecture of our model looks like:\n",
    "\n",
    "<p align=\"center\"><img src=\"https://cezannec.github.io/assets/cnn_text/complete_text_classification_CNN.png\" width=\"75%\" align=\"center\"></p>\n",
    "\n",
    "We will be using an embedding layer loaded with a word2vec model, followed by convolution layers, and then a linear layer.\n",
    "\n",
    "We will be using the Clickbait and Web of Science dataset for this task.\n",
    "\n",
    "**Please make sure you don't skip Q0 as it will help you understand error related to state_dict keys better**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c6c8b",
   "metadata": {
    "id": "5hBTTf_0bDWd"
   },
   "source": [
    "## 2.1: Implementing CNN Classifier [10pts]\n",
    "In the **cnn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward_embed</strong>\n",
    "  * <strong>forward_convs</strong>\n",
    "  * <strong>forward</strong>\n",
    "  \n",
    "We have included local tests in 2.1.3 for you to test your implementation of the CNN functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a187681",
   "metadata": {
    "id": "BlQWYkt6bjPM"
   },
   "source": [
    "### 2.1.1: Pre-Processing Data [No Points]\n",
    "\n",
    "Run the below cell to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ec4d189e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "QtXq7iy3bwrs",
    "outputId": "e4849779-987a-4a07-d1bb-c4cb867814bc"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def preprocess(data):\n",
    "    preprocessed_data = []\n",
    "    for text in data:\n",
    "        tokens = simple_preprocess(text, deacc=True)\n",
    "        preprocessed_data.append(tokens)\n",
    "    return preprocessed_data\n",
    "\n",
    "preprocessed_x_train = preprocess(x_train)\n",
    "preprocessed_x_train_wos = preprocess(x_train_wos)\n",
    "\n",
    "preprocessed_x_test = preprocess(x_test)\n",
    "preprocessed_x_test_wos = preprocess(x_test_wos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f306f9a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "_M0alpCXcN3N",
    "outputId": "6ffd3641-ff5e-4366-958d-f18399a31bd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: \n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Use cuda if present\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running: \")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae29d17",
   "metadata": {
    "id": "vOr_wpjNdGnj"
   },
   "source": [
    "### 2.1.2: Utility functions for training Word2Vec Model [No Points]\n",
    "\n",
    "Run the below cells for making word2vec model, vectors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a59aa366",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "3gjLdwNOdOYd",
    "outputId": "2315178e-7fd3-42bd-c555-8af5915f7976"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "vector_size = 500\n",
    "window = 3\n",
    "min_count = 1\n",
    "workers = 3\n",
    "sg = 1\n",
    "\n",
    "# Function to train word2vec model\n",
    "def make_word2vec_model(data, padding=True, sg=1, min_count=1, vector_size=500, workers=3, window=3):\n",
    "    data.append(['pad'])\n",
    "    w2v_model = Word2Vec(data, min_count=min_count, vector_size=vector_size, workers=workers, window=window, sg=sg)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4db71b9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DTUjqQnjdOUz",
    "outputId": "11051581-803c-477e-9788-af3d12a9e201"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "def make_word2vec_vector(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel.wv.key_to_index:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel.wv.key_to_index[word]\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device=device).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3b52f59d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "PrOTzz5gddgj",
    "outputId": "70681d17-e12c-44bd-8be2-fd7be0c7b8c9"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "def make_target(label):\n",
    "    return torch.tensor([label], dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e1034e",
   "metadata": {},
   "source": [
    "### 2.1.3: Local Tests for CNN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **cnn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bdb6c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for CNN Implementation \n",
      "\n",
      "Your forward_embed works as expected: True\n",
      "Your forward_convs works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "from local_tests.cnn_test import CNN_Test\n",
    "torch.manual_seed(10)\n",
    "local_test = CNN_Test()\n",
    "\n",
    "# creating the local test dataset for CNN\n",
    "local_test_dataset = local_test.input_sequences\n",
    "preprocessed_x_local_test = preprocess(local_test_dataset)\n",
    "\n",
    "w2vmodel_test = make_word2vec_model(preprocessed_x_local_test, padding=True, sg=sg, min_count=min_count, vector_size=vector_size, workers=workers, window=window)\n",
    "cnn_model = CNN(w2vmodel_test, num_classes=2, window_sizes=(1,2,3,5))\n",
    "cnn_model.load_state_dict(torch.load('./local_tests/basic_cnn_model.pt'))    # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n",
    "cnn_model.eval()\n",
    "\n",
    "max_sen_len = max(map(len, preprocessed_x_local_test))\n",
    "padding_idx = w2vmodel_test.wv.key_to_index['pad']\n",
    "def make_word2vec_vector_test(sentence):\n",
    "    padded_X = [padding_idx for i in range(max_sen_len)]\n",
    "    i = 0\n",
    "    for word in sentence:\n",
    "        if word not in w2vmodel_test.wv.key_to_index:\n",
    "            padded_X[i] = 0\n",
    "        else:\n",
    "            padded_X[i] = w2vmodel_test.wv.key_to_index[word]\n",
    "        i += 1\n",
    "    return torch.tensor(padded_X, dtype=torch.long, device='cpu').view(1, -1)\n",
    "x_local_test = make_word2vec_vector_test(preprocessed_x_local_test[0])\n",
    "\n",
    "print('Local Tests for CNN Implementation \\n')\n",
    "\n",
    "# Local test for forward_embed\n",
    "embeddings = cnn_model.forward_embed(x_local_test)\n",
    "forward_embed_test = (embeddings.shape == local_test.embeddings.shape) and (torch.allclose(embeddings, local_test.embeddings, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_embed works as expected:', forward_embed_test)\n",
    "if not forward_embed_test and device == torch.device(\"cuda\") :\n",
    "    print('  *** If you are using a GPU or Google Colab, it is possible for this local test to fail with a correct implementation. We recommend checking your submission against Gradescope.')\n",
    "\n",
    "# Local test for forward_cnn\n",
    "convs_output = cnn_model.forward_convs(local_test.embeddings)\n",
    "forward_convs_test = (convs_output.shape == local_test.convs_output.shape) and (torch.allclose(convs_output, local_test.convs_output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_convs works as expected:', forward_convs_test)\n",
    "\n",
    "# Local test for forward\n",
    "x_local_test = torch.concat((x_local_test, make_word2vec_vector_test(preprocessed_x_local_test[1]), \\\n",
    "                             make_word2vec_vector_test(preprocessed_x_local_test[2])), axis=0)\n",
    "cnn_forward_output = cnn_model.forward(x_local_test)\n",
    "forward_test = (cnn_forward_output.shape == local_test.output.shape) and (torch.allclose(cnn_forward_output, local_test.output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward works as expected:', forward_test)\n",
    "if not forward_test and device == torch.device(\"cuda\") :\n",
    "    print('  *** If you are using a GPU or Google Colab, it is possible for this local test to fail with a correct implementation. We recommend checking your submission against Gradescope.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7e418",
   "metadata": {
    "id": "fXuJ6ouncC8Z"
   },
   "source": [
    "## 2.2: Classifying Clickbait Dataset using CNN [No Points]\n",
    "\n",
    "Run the below cell to classify the Clickbait train and test dataset using the CNN functions that you have already implemented in 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "18ed03c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "lurnaUoUXCcU",
    "outputId": "dece0006-ceab-4123-cb16-7e728f2e6f3c"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train, padding=True, sg=sg, min_count=min_count, vector_size=vector_size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a355b37",
   "metadata": {},
   "source": [
    "Because CNN requires the input data to be of the same length. We use the embedding of the \"pad\" word as the padding vector. Notice that this choice is just a convention and other tokens could also work for this purpose. In more complex language model, there will be a dedicated '\\<pad\\>' token for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e473b285",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "MnRN7kn7XCe6",
    "outputId": "39df6412-550c-4e4c-c892-3473877470da"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "max_sen_len = max(map(len, preprocessed_x_train))\n",
    "padding_idx = w2vmodel.wv.key_to_index['pad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "301b82b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "zIdO6zAsUMGV",
    "outputId": "d7cce669-26ac-45cc-e11c-827cfd122925"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 3122.340118\n",
      "loss on epoch 1: 2819.890108\n",
      "loss on epoch 2: 2718.865467\n",
      "loss on epoch 3: 2625.852622\n",
      "loss on epoch 4: 2586.398618\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train)))\n",
    "    random.shuffle(shuffled_i)\n",
    "\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train[index])\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train[index])\n",
    "\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d83982f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "aOiTWeR6VDXk",
    "outputId": "b02e1d0d-5194-4b47-faec-cdba1a3b330f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using CNN : 0.941\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for index in range(len(y_test)):\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_test[index])\n",
    "        probs = model(bow_vec)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy()[0])\n",
    "        t = make_target(y_test[index]).cpu().numpy()[0]\n",
    "        original_lables_cnn.append(make_target(y_test[index]).cpu().numpy()[0])\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using CNN : {:.3f}\".format(accuracy_score(original_lables_cnn, cnn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9633424",
   "metadata": {
    "id": "lRXO38UrmQ18"
   },
   "source": [
    "## 2.3: Classifying Web of Science Dataset using CNN [5pts]\n",
    "\n",
    "Run the below cell to classify the WoS train and test dataset using the CNN functions that you have already implemented in 2.\n",
    "\n",
    "**You must reach an accuracy of >= 50% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ba115b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XUyZvrX3mWXj",
    "outputId": "90050d4c-c393-483d-c76d-d7cc475e3ce7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "# Train Word2vec model\n",
    "w2vmodel = make_word2vec_model(preprocessed_x_train_wos, padding=True, sg=sg, min_count=min_count, vector_size=vector_size, workers=workers, window=window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa8d0820",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "dP07m73fRM44",
    "outputId": "28f17390-69d5-4178-f8ec-9a51ae9dbaa6"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "# load_pt = False\n",
    "# max_sen_len = max(map(len, preprocessed_x_train_wos))\n",
    "# padding_idx = w2vmodel.wv.vocab['pad'].index\n",
    "\n",
    "# Uncomment for use if there is a discrepancy in testing accuracy between notebook and gradescope\n",
    "load_pt = True\n",
    "train_dataset = torch.load('./data/cnn_train_dataset_wos.pt')\n",
    "test_dataset = torch.load('./data/cnn_test_dataset_wos.pt')\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f0cade6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "id": "HZPVaPsvmoDR",
    "outputId": "21294fa2-48a5-455e-c7fa-fd8d5d9c602f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 2106.281955\n",
      "loss on epoch 5: 1453.498466\n",
      "loss on epoch 10: 1258.855585\n",
      "loss on epoch 15: 1145.853289\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from cnn import CNN\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = CNN(w2vmodel, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    shuffled_i = list(range(0,len(y_train_wos)))\n",
    "    random.shuffle(shuffled_i)\n",
    "\n",
    "    for index in range(len(shuffled_i)):\n",
    "        model.zero_grad()\n",
    "        bow_vec = make_word2vec_vector(preprocessed_x_train_wos[index]) if not load_pt else train_dataset[index][0].unsqueeze(0).to(device)\n",
    "        outputs = model(bow_vec)\n",
    "        y = make_target(y_train_wos[index] if not load_pt else train_dataset[index][1])\n",
    "        \n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 5 == 0:    \n",
    "        print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ca0f29f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E3bSg3HCYnIS",
    "outputId": "e47cc8c4-3846-46bc-f7b2-7120947e8263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using CNN : 0.630\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "cnn_predictions = []\n",
    "original_lables_cnn = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        probs = model(x)\n",
    "        _, predicted = torch.max(probs.data, 1)\n",
    "        cnn_predictions.append(predicted.cpu().numpy())\n",
    "        original_lables_cnn.append(y)\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using CNN : {:.3f}\".format(accuracy_score(np.hstack(original_lables_cnn), np.hstack(cnn_predictions)))) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e46f9f1",
   "metadata": {
    "id": "px4Og3agxxkY"
   },
   "source": [
    "### ðŸ¥ <font color='darkred'>Submit these files to Gradescope</font><a id='find_chicken'></a>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_cnn_model.pt` and the `cnn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 50% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28674966",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "XwwCsXxux2nS",
    "outputId": "7b88e6a6-9122-4ed7-a223-c7892856f9b7"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_cnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab122c32",
   "metadata": {
    "id": "hJaO3vd_oP-Z"
   },
   "source": [
    "# Q3: Classification with RNN [15pts]\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are a powerful class of neural networks that are designed to handle sequence prediction problems. RNNs operate by maintaining a hidden state that captures the information of all the previous elements in the sequence. For text data, this means that each word is not looked at in isolation, but rather as part of the overall context provided by the words that came before it. The hidden state is updated at each step of the sequence, which allows the network to make predictions based on all previously seen data. A bi-directional RNN is a slight modification to the vanilla RNN, where it maintains two hidden states, one that captures information from the previous elements, and the other that captures information from the upcoming elements. This usually allows it to perform better since it takes into account past and future data.\n",
    "\n",
    "RNN's may or may not perform well depending on the task at hand. In the context of Customer Feedback Analysis, RNN's excel at understanding the overall sentiment of a sentence/review. For this example of a review: \"I initially had issues with the product, but their customer service was outstanding, and now I love it!\", an RNN can understand the overall positive sentiment despite the initial negative phrase.\n",
    "However, RNN's may not be appropriate to use for categorizing feedback. For example: In order to categorize customer feedback into 'Product', 'Service', or 'Delivery', RNN's may be overkill. A simple keyword detection approach would suffice for such a task.\n",
    "\n",
    "In this section we will be using recurrent neural networks for classification. Below is a diagram of our model architecture, **note how the hidden state of the last word in the forward direction and the hidden state of the first word in the reverse direction are both fed into the dense linear layer.** \n",
    "<!---\n",
    "<p align=\"center\"><img src=\"https://www.tensorflow.org/static/text/tutorials/images/bidirectional.png\" width=\"75%\" align=\"center\"></p>\n",
    "-->\n",
    "![title](data/img/RNN.png)\n",
    "**NOTE**: It is important to note that we use the hidden state corresponding to the last word in the forward direction, which isn't necessarily the hidden state of the last time-step. For example if we have 3 sentences of lengths 10, 15 and 20, all 3 sentences will be padded up to 20 tokens during the pre-processing and vectorizing step (which has been implemented in the vectorize_batch( ) function in 3.2). We will be using the hidden state corresponding to the last word in each sentence (which will be $h_{10}^f$, $h_{15}^f$ and $h_{20}^f$ respectively), not the hidden state of the last time-step (which is $h_{20}^f$ for all 3 sentences).\n",
    "\n",
    "We will be using an embedding layer, followed by a bi-directional RNN layer, and then a linear layer.\n",
    "\n",
    "We will use the Clickbait and Web of Science dataset for this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe10a0",
   "metadata": {
    "id": "alo7oi32yrwp"
   },
   "source": [
    "## 3.1: Implementing RNN Classifier [10pts]\n",
    "In the **rnn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward_embed</strong>\n",
    "  * <strong>forward_rnn</strong>\n",
    "  * <strong>forward_concat</strong>\n",
    "  * <strong>forward</strong>\n",
    "\n",
    "We have included local tests in 3.2.2 for you to test your implementation of the RNN functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f2bab",
   "metadata": {
    "id": "Aajl3628zAkp"
   },
   "source": [
    "### 3.1.1: Pre-Processing Data [No Points]\n",
    "\n",
    "Run the below cells to load functions for building vocabulary and tokenizing the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f3600e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8qk1qpnIzCwe",
    "outputId": "5f75fc50-8aaa-4a09-dc2e-f78bcc8ed8d3"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def build_vocabulary(datasets):\n",
    "    for dataset in datasets:\n",
    "        for text in dataset:\n",
    "            yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(build_vocabulary([x_train]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab.set_default_index(vocab[\"<UNK>\"])\n",
    "\n",
    "vocab_wos = build_vocab_from_iterator(build_vocabulary([x_train_wos]), min_freq=1, specials=[\"<UNK>\"])\n",
    "vocab_wos.set_default_index(vocab[\"<UNK>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e7d74b",
   "metadata": {},
   "source": [
    "## 3.2: Classifying Clickbait Dataset using RNN [5pts]\n",
    "\n",
    "In distinguishing between clickbait and non-clickbait titles, an RNN can use the context provided by the sequence of words to understand nuances and patterns that are characteristic of clickbait, such as sensationalist language or incomplete information that entices readers to click.\n",
    "\n",
    "Run the cells below to classify the Clickbait train and test dataset using the RNN functions that you have implemented. \n",
    "\n",
    "**You must reach an accuracy of >= 85% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1389f81",
   "metadata": {},
   "source": [
    "### 3.2.1 : Create the Dataloaders [No Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "820d1dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_words = 0\n",
    "for t in x_train:\n",
    "    max_words = max(max_words, len(vocab(tokenizer(t))))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] ## Bringing all samples to max_words length.\n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d6ae6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "train_dataset = list(map(lambda y, x: (y, x), y_train, x_train))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test, x_test))\n",
    "\n",
    "# Uncomment for use if there is a discrepancy in testing accuracy between notebook and gradescope\n",
    "# train_dataset = torch.load('./data/rnn_train_dataset_cb.pt')\n",
    "# test_dataset = torch.load('./data/rnn_test_dataset_cb.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1024, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cbd3c0",
   "metadata": {},
   "source": [
    "### 3.2.2: Local Tests for RNN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **rnn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c74bf9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for RNN Implementation \n",
      "\n",
      "Your forward_embed works as expected: True\n",
      "Your forward_rnn works as expected: True\n",
      "Your forward_concat works as expected: True\n",
      "Your forward works as expected: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from local_tests.rnn_test import RNN_Test\n",
    "torch.manual_seed(10)\n",
    "\n",
    "local_test = RNN_Test()\n",
    "rnn_model = RNN(vocab, num_classes=2)\n",
    "rnn_model.load_state_dict(torch.load('./local_tests/basic_rnn_model.pt'))    # upload default weights. If this errors out, make sure you have initialized the layers correctly.\n",
    "rnn_model.eval()\n",
    "\n",
    "# creating a vectorized batch from the sample datapoints\n",
    "local_test_dataset = list(map(lambda y, x: (y, x), local_test.output_labels, local_test.input_sequences))\n",
    "X_localtest, X_len_localtest, Y_localtest = vectorize_batch(local_test_dataset)\n",
    "\n",
    "print('Local Tests for RNN Implementation \\n')\n",
    "\n",
    "# Local test for forward_embed\n",
    "embeddings = rnn_model.forward_embed(X_localtest)\n",
    "forward_embed_test = (embeddings.shape == local_test.embeddings.shape) and (torch.allclose(embeddings, local_test.embeddings, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_embed works as expected:', forward_embed_test)\n",
    "\n",
    "# Local test for forward_rnn\n",
    "rnn_output = rnn_model.forward_rnn(local_test.embeddings, X_len_localtest)\n",
    "forward_rnn_test = (rnn_output.shape == local_test.rnn_output.shape) and (torch.allclose(rnn_output, local_test.rnn_output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward_rnn works as expected:', forward_rnn_test)\n",
    "\n",
    "# Local test for forward_concat\n",
    "concat = rnn_model.forward_concat(local_test.rnn_output, X_len_localtest)\n",
    "forward_concat_test = (concat.shape == local_test.concat.shape) and (torch.allclose(concat, local_test.concat))\n",
    "print('Your forward_concat works as expected:', forward_concat_test)\n",
    "\n",
    "# Local test for forward\n",
    "output = rnn_model.forward(X_localtest, X_len_localtest)\n",
    "forward_test = (output.shape == local_test.output.shape) and (torch.allclose(output, local_test.output, rtol=0.0001, atol=0.0001))\n",
    "print('Your forward works as expected:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae36545c",
   "metadata": {},
   "source": [
    "### 3.2.3: Train and Evaluate on the Clickbait Dataset [5pts]\n",
    "\n",
    "**You must reach an accuracy of >= 85% to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df518b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available for running: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device available for running:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aa1f7e83",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "id": "zlXccqKokN-u",
    "outputId": "bc849b0f-43ad-4783-f8ad-da88656026d0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:13<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 7.806681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:12<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 2.767155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:13<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 1.246340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:12<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 0.489087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:12<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 0.199175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "model = RNN(vocab, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "        loss = criterion(outputs, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bd5f6dc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "UjopZ85QsEcV",
    "outputId": "bac143d6-28f5-4f83-a18f-b00176d82080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on Clickbait Dataset using RNN  : 0.964\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, X_len, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on Clickbait Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539abb0",
   "metadata": {
    "id": "i7JXqy4Yzj7R"
   },
   "source": [
    "### ðŸ¦‰ <font color='darkred'>Submit these files to Gradescope</font>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_rnn_model.pt` and the `rnn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 85% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "45dbeeb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "YIoYfQJtzkdX",
    "outputId": "81b2dfae-81e3-4576-d8e9-58e6e6a0647a"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_rnn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef49681f",
   "metadata": {
    "id": "_sW4Am9kvdGA"
   },
   "source": [
    "## 3.3: Classifying Web of Science Dataset using RNN [No Points]\n",
    "\n",
    "Run the cells below to classify the WoS train and test dataset using the RNN functions that you have already implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc91268",
   "metadata": {},
   "source": [
    "### 3.3.1: Create the Dataloaders [No Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e57f937f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "DPZE5g1uRI_I",
    "outputId": "5b47c0ad-5e17-4424-c482-2d102e746fbe"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "max_words = 0\n",
    "for t in x_train_wos:\n",
    "    max_words = max(max_words, len(vocab_wos(tokenizer(t))))\n",
    "\n",
    "def vectorize_batch(batch):\n",
    "    Y, X = list(zip(*batch))\n",
    "    X = [vocab_wos(tokenizer(text)) for text in X] ## Tokenize and map tokens to indexes\n",
    "    X_len = [len(text) for text in X]\n",
    "    X = [tokens+([0]* (max_words-len(tokens))) if len(tokens)<max_words else tokens[:max_words] for tokens in X] \n",
    "    return torch.tensor(X, dtype=torch.int32), torch.tensor(X_len), torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "58c54e6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "1ypsgOIIRUFm",
    "outputId": "6c795bf1-88db-46e4-ec3e-606d7aaf0dfb"
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "train_dataset = list(map(lambda y, x: (y, x), y_train_wos, x_train_wos))\n",
    "test_dataset = list(map(lambda y, x: (y, x), y_test_wos, x_test_wos))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, collate_fn=vectorize_batch, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=vectorize_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89613f34",
   "metadata": {},
   "source": [
    "### 3.3.2: Train and Evaluate on the Web of Science dataset [No Points]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b85c6573",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "id": "195yI5vSvhWr",
    "outputId": "1b605091-1ba2-4735-df9d-3f53477f8403"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:16<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 0: 17.676069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 1: 16.438302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:15<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 2: 15.717597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:15<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 3: 15.286072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 4: 14.705522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 5: 13.972790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 6: 13.353238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 7: 12.659054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:14<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 8: 12.119202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:15<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 9: 11.035678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:15<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 10: 10.316952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:15<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss on epoch 11: 9.300102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|â–Š         | 1/13 [00:02<00:31,  2.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[80]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m loss = criterion(outputs, Y)\n\u001b[32m     25\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m loss.backward()\n\u001b[32m     27\u001b[39m optimizer.step()\n\u001b[32m     29\u001b[39m total_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/nlp_hw3/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    514\u001b[39m         Tensor.backward,\n\u001b[32m    515\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m         inputs=inputs,\n\u001b[32m    521\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m torch.autograd.backward(\n\u001b[32m    523\u001b[39m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs=inputs\n\u001b[32m    524\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Applications/anaconda3/envs/nlp_hw3/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    261\u001b[39m     retain_graph = create_graph\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m Variable._execution_engine.run_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    267\u001b[39m     tensors,\n\u001b[32m    268\u001b[39m     grad_tensors_,\n\u001b[32m    269\u001b[39m     retain_graph,\n\u001b[32m    270\u001b[39m     create_graph,\n\u001b[32m    271\u001b[39m     inputs,\n\u001b[32m    272\u001b[39m     allow_unreachable=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    273\u001b[39m     accumulate_grad=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    274\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from rnn import RNN\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "model = RNN(vocab_wos, num_classes=NUM_CLASSES)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, X_len, Y in tqdm(train_loader):\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "        loss = criterion(outputs, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(\"loss on epoch %i: %f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fcd5a8ca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ltNFDxdyvt-k",
    "outputId": "f9f407e2-4540-4955-c8db-b4b5543e1eb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using RNN  : 0.490\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, X_len, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X, X_len)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "print(\"Test Accuracy on WoS Dataset using RNN  : {:.3f}\".format(accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a8561e",
   "metadata": {
    "id": "Kb6rhadO0UEq"
   },
   "source": [
    "**NOTE** : RNN alone is not able to perform well on the WoS dataset and that can be attributed to the very limited data with large vocabulary and lack of embedding structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2efa3",
   "metadata": {},
   "source": [
    "# Q4: Classification with NN [4pts Bonus Extra Credit]\n",
    "\n",
    "A Neural Network (NN) is composed of layers of neurons stacked together, in order to learn a complex non-linear mapping between the input(s) and output(s). The layers are usually fully connected, which means that each neuron of layer 'i' is connected to every neuron of layer 'i-1', and each neuron computes a weighted summation of it's inputs, which is usually passed through a non-linear activation function.\n",
    "\n",
    "An example of an application where neural networks perform well is classifying emails as Spam or Not Spam, where we can use features such as the presence of certain words like 'free', 'offer', 'click here' etc. to determine if the email is spam. However, for more complex tasks like categorizing emails into specific folders (e.g., 'Work', 'Personal', 'Promotions') based on the content's tone, urgency, and subject matter, traditional NNs might not perform well because they cannot process the sequence and context of words effectively.\n",
    "\n",
    "You may have noticed that both CNN and RNN did not perform as well on the Web of Science dataset as other machine learning algorithms that we explored in previous homeworks. It is possible that the limited dataset compared to the complexity of the CNN and RNN network was not sufficient to train these networks to a high enough accuracy. In the table below, we compare the performace of the classifiers we have seen on the Web of Science dataset.\n",
    "\n",
    "| Classifer | Test Accuracy on WoS |\n",
    "| :-: | :-: |\n",
    "|Logistic Regression | ~ 75% |\n",
    "|Perceptron | ~ 81% |\n",
    "|SVM | ~ 81% |\n",
    "| CNN | ~ 68% |\n",
    "| RNN | ~ 49% |\n",
    "\n",
    "\n",
    "In this bonus question, we ask you to explore how a two layer neural net would fare on the Web of Science dataset. You will need to implement a two layer neural net using pytorch's linear layers as well as write your own training loop to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6122eb78",
   "metadata": {},
   "source": [
    "### 4.1: Implementing NN Classifier [2pts Bonus Extra Credit]\n",
    "Implement your two layer neural net. We require your model to have exactly two linear layers to pass the autograder and that you adhere to the specified input and output shapes. You are free to design the rest of your network as you see fit and use any non-linearity or dropout layers to obtain the necessary accuracy.\n",
    "\n",
    "In the **nn.py** file complete the following functions:\n",
    "  * <strong>\\_\\_init__</strong>\n",
    "  * <strong>forward</strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25bd854",
   "metadata": {},
   "source": [
    "### 4.2: Local Tests for NN Functions [No Points]\n",
    "You may test your implementation of the functions contained in **nn.py** in the cell below. Feel free to comment out tests for functions that have not been completed yet. See [Using the Local Tests](#using_local_tests) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f9951b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Tests for NN Implementation \n",
      "\n",
      "Your forward accepts and outputs the expected shapes: True\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from nn import NN\n",
    "from local_tests.nn_test import NN_Test\n",
    "\n",
    "local_test = NN_Test()\n",
    "sample_input = torch.cat([torch.tensor(sample_input[0]).unsqueeze(0) for sample_input in torch.load('./data/bonus_train_wos.pt')[:3]])\n",
    "nn_model = NN(feat_size = sample_input.shape[-1], num_classes=4)\n",
    "\n",
    "print('Local Tests for NN Implementation \\n')\n",
    "\n",
    "# Local test for forward\n",
    "output = nn_model.forward(sample_input)\n",
    "forward_test = (output.shape == local_test.sample_output.shape)\n",
    "print('Your forward accepts and outputs the expected shapes:', forward_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4213c6",
   "metadata": {},
   "source": [
    "### 4.3: Loading and Preprocessing the Web of Science Dataset [No Points]\n",
    "For this exercise, we will use the Web of Science Dataset that has been encoded using sklearn's TFIDF Vectorizer and then reduced to a dimension of 1024 through PCA dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3958350",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = torch.load('./data/bonus_train_wos.pt')\n",
    "test_dataset = torch.load('./data/bonus_test_wos.pt')\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128,  shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77780137",
   "metadata": {},
   "source": [
    "### 4.4: Training Your Model & Testing Accuracy [2pts Bonus Extra Credit]\n",
    "Here you will write your own training loop. You are free to decide on the criterion, optimizer, and various hyperparameters required for training. Keep in mind that you are building a classifier and some criterions are more suited for this task than others. Your model must be able to accept the data from train_loader and output the expected shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4515aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 933.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 18.0291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 984.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 17.9003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 762.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 17.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1050.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 17.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 852.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 17.1210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 894.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 16.6061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1029.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 15.9694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 943.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 15.1516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 251.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 14.2740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1213.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 13.2154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 866.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 12.2415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 901.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 11.1412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 862.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 10.1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1101.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 9.0992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 951.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 8.1583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1030.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 7.2899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 951.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 6.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1085.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 5.7429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 991.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 5.1712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:00<00:00, 1028.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 4.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nn import NN\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "NUM_CLASSES = 4\n",
    "feat_size = train_dataset[0][0].shape[0]\n",
    "model = NN(feat_size, num_classes=NUM_CLASSES)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "N_EPOCHS = 20\n",
    "\n",
    "model.train()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for X, Y in tqdm(train_loader):  \n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        outputs = model(X) \n",
    "        loss = criterion(outputs, Y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c47189",
   "metadata": {},
   "source": [
    "After you have trained your model, run the below cell to see how your trained model performs with the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7d152c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on WoS Dataset using NN  : 0.840\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    Y_truth, Y_preds = [],[]\n",
    "    for X, Y in test_loader:\n",
    "        X = X.to(device)\n",
    "        outputs = model(X)\n",
    "\n",
    "        Y_truth.append(Y)\n",
    "        Y_preds.append(outputs)\n",
    "\n",
    "    Y_truth = torch.cat(Y_truth)\n",
    "    Y_preds = torch.cat(Y_preds)\n",
    "\n",
    "curr_acc_score = accuracy_score(Y_truth.cpu().detach().numpy(), F.softmax(Y_preds, dim=-1).argmax(dim=-1).cpu().detach().numpy())\n",
    "print(\"Test Accuracy on WoS Dataset using NN  : {:.3f}\".format(curr_acc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7453a90",
   "metadata": {},
   "source": [
    "### ðŸ¦¥ <font color='darkred'>Submit these files to Gradescope</font>\n",
    "**Run the cell below to save the state of your model. You will be required to upload `best_nn_model.pt` and the `nn.py` file to Gradescope for accuracy evaluation. You must reach an accuracy of >= 80% on the above test dataset to receive credit for this section.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b49ea973",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "### DO NOT CHANGE THIS CELL ###\n",
    "###############################\n",
    "\n",
    "torch.save(model.state_dict(), 'best_nn_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a69d4b",
   "metadata": {},
   "source": [
    "**Congrats, you have reached the end of Homework 3 ðŸ˜Ž**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-Np3UUmtFUjd",
    "4TLUiFFR7wlL",
    "dRvybL9rYxcQ",
    "_sW4Am9kvdGA"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "nlp_hw3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
